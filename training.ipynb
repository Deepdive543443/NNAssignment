{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import config\n",
    "import numpy as np\n",
    "from models import Convsfig as Fully_convsfig\n",
    "from utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchsummary import summary\n",
    "from tqdm import notebook\n",
    "tqdm = notebook.tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea88dd7110e3493c875bbf984441c9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CIFAR10\\cifar-10-python.tar.gz to CIFAR10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(\"CIFAR10\", train=True, transform=tranform, download=True) # Set download to False if you already have dataset downloaded\n",
    "test_dataset = CIFAR10(\"CIFAR10\", train=False, transform=tranform, download=True)\n",
    "loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, pin_memory=True, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, pin_memory=True, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve our task on exploring different hyperparameters' effect on model, we define a simple convolutional neural networks below.\n",
    "It has three hidden layers(two convolution layers and a fully connected layer at the end).\n",
    "Each conv layer has a pooling layer and an activation function at the end.\n",
    "Adding batchnorm or switching activation function by hyperparameters.\n",
    "\n",
    "In the upcoming section, we will train this model with a list of different parameters, then compare their different in performance.\n",
    "\n",
    "The torch summary library seems bugged in our assignment, it displays and count the parameters from some layers twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]          15,616\n",
      "            Conv2d-2           [-1, 64, 32, 32]          15,616\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "              ReLU-4           [-1, 64, 32, 32]               0\n",
      "         ConvBlock-5           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7          [-1, 128, 16, 16]         663,680\n",
      "            Conv2d-8          [-1, 128, 16, 16]         663,680\n",
      "              ReLU-9          [-1, 128, 16, 16]               0\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "        ConvBlock-11          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-12            [-1, 128, 8, 8]               0\n",
      "          Flatten-13                 [-1, 8192]               0\n",
      "           Linear-14                   [-1, 10]          81,930\n",
      "================================================================\n",
      "Total params: 1,440,522\n",
      "Trainable params: 1,440,522\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.00\n",
      "Params size (MB): 5.50\n",
      "Estimated Total Size (MB): 9.51\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:[1]: 100%|██████████████████████████████████████████| 40/40 [00:03<00:00, 11.65it/s, accuracy=0.667, loss=1.21]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5b04b78a0dfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFOLD_SPLIT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mconv_acc_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Cross_val_score:{conv_acc_list}   time:{time}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Download\\NNAssignment-main\\utils.py\u001b[0m in \u001b[0;36mKFold_validation\u001b[1;34m(model, dataset, val_epochs, shuffle, split, lr, batch_size, mix_up_activation, weight_decay)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmix_up_activation\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmix_up_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmix_up_activation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0macc_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Download\\NNAssignment-main\\utils.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optim, loader, epoch, scheduler, lr_decay)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mtrues\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Download\\NNAssignment-main\\utils.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(outputs, labels)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0mT\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mL\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make model by config list\n",
    "# list: [f, k, s, p], conv\n",
    "# tuple: (k, s, p), pooling\n",
    "# int: channels, Linear(fully_connected)\n",
    "# str: single flatten or global avg pooling\n",
    "\n",
    "layers = [[64, 9, 1, 4], # A block of convolutional layer with 64 output channels, kernel size 9, stride 1, padding 4\n",
    "          (2, 2, 0), # A pooling layer with kernel size 2, stride 2.\n",
    "          [128, 9, 1, 4],# A block of convolutional layer with 128 output channels, kernel size 9, stride 1, padding 4\n",
    "          (2, 2, 0),# A pooling layer with kernel size 2, stride 2.\n",
    "          10]# fully connected layers with 10 output\n",
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "\n",
    "acc, time = KFold_validation(model, train_dataset, shuffle=False, val_epochs=5, split=config.KFOLD_SPLIT, lr=config.LEARNING_RATE)\n",
    "conv_acc_list = sum(acc)/len(acc)\n",
    "print(f\"Cross_val_score:{conv_acc_list}   time:{time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Config of baseline model\n",
    "layers = [[64, 9, 1, 4],(2,2,0),[128, 9, 1, 4],(2,2,0),10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and accuracy curve of baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"base_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"lr_1e-2\",lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"lr_1e-6\",lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "learning_rate decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "milestone = [15,18,20,22,24]\n",
    "init_lr = 0.1\n",
    "gamma = 0.1\n",
    "\n",
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"lr_decay\",lr=init_lr, lr_decay=True, epochs=200, milestone=milestone, gamma=gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNorm with batch size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,use_bn=True).to(config.DEVICE)\n",
    "batch16_loader = DataLoader(train_dataset, batch_size=16, pin_memory=True, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, batch16_loader, test_loader,\"batchnorm_16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNorm with batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,use_bn=True).to(config.DEVICE)\n",
    "batch16_loader = DataLoader(train_dataset, batch_size=64, pin_memory=True, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, batch16_loader, test_loader,\"batchnorm_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Norm with batch size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,use_bn=True).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"batchnorm_256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,pooling=\"avg\").to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"avg_pooling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,init=\"He\").to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"He_init\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,init=\"Xavier\").to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"Xavier_init\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier with TanH activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,init=\"Xavier\",activation=nn.Tanh()).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"Xavier_TanH_init\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TanH activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,activation=nn.Tanh()).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"TanH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "without activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,activation=nn.Identity()).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"without_act\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop out rate 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,dropout=0.2).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"drop_out_0.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop out rate 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers,dropout=0.7).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"drop_out_0.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"weight_decay_1e-4\", weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"weight_decay_1e-3\", weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "summary(model,(3,32,32))\n",
    "draw_loss_acc_curve(model, loader, test_loader,\"weight_decay_1e-2\", weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "layers = [[64, 9, 1, 4],(2,2,0),[128, 9, 1, 4],(2,2,0),10]\n",
    "model = Fully_convsfig(configs = layers).to(config.DEVICE)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "optimizer = optim.Adam(model.parameters(),  lr=config.LEARNING_RATE)\n",
    "for epoch in range(150):\n",
    "    #Mix up training\n",
    "    loss = mix_up_training(model, optimizer, loader, epoch, non_linearity = \"sigmoid\")\n",
    "    train_loss.append(loss)\n",
    "    #training accuracy\n",
    "    acc, _ = test(model, loader, epoch)\n",
    "    train_acc.append(acc)\n",
    "    #testin loss and accuracy\n",
    "    acc, loss = test(model, test_loader, epoch)\n",
    "    test_loss.append(loss)\n",
    "    test_acc.append(acc)\n",
    "torch.save((train_loss, test_loss, train_acc, test_acc), \"result/convs_curve_mix_up_softmax.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected optimal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "layers = [[64, 9, 1, 4],(2,2,0),[128, 9, 1, 4],(2,2,0),10]\n",
    "model = Fully_convsfig(configs = layers,use_bn=True).to(config.DEVICE)\n",
    "\n",
    "mix_up_train_dataset = CIFAR10(\"CIFAR10\", train=True, transform=tranform_aug)\n",
    "\n",
    "mixup_loader = DataLoader(train_dataset, batch_size=256, pin_memory=True, shuffle=config.SHUFFLE, num_workers=config.NUM_WORKERS)\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "optimizer = optim.Adam(model.parameters(),  lr=config.LEARNING_RATE)\n",
    "#\n",
    "for epoch in range(150):\n",
    "    #Mix up training\n",
    "    loss = mix_up_training(model, optimizer, mixup_loader, epoch, non_linearity = \"softmax\")\n",
    "    train_loss.append(loss)\n",
    "    #training accuracy\n",
    "    acc, _ = test(model, loader, epoch)\n",
    "    train_acc.append(acc)\n",
    "    #testin loss and accuracy\n",
    "    acc, loss = test(model, test_loader, epoch)\n",
    "    test_loss.append(loss)\n",
    "    test_acc.append(acc)\n",
    "torch.save((train_loss, test_loss, train_acc, test_acc), \"result/convs_curve_mix_up_softmax_aug.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
